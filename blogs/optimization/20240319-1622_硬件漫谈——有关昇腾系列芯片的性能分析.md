# 硬件漫谈——有关昇腾Atlas加速卡的性能分析

## 引子
在当今这个数据驱动的时代，人工智能（AI）的应用日益广泛，从自动驾驶到智能语音助手，从医疗影像分析到复杂的金融模型预测，都离不开AI算法的支持。然而，这些高级功能的实现并非易事，它们背后需要强大的硬件基础来支撑复杂的模型推理过程。硬件，尤其是专门为AI设计的加速芯片，已经成为推动AI技术发展的关键因素。

在过去的一段时间里，NVIDIA凭借其出色的AI加速芯片，在市场上占据了绝对主导地位。它的产品广泛应用于各种AI场景，成为众多研究者和开发者的首选。然而，近年来全球供应链的问题使得NVIDIA的AI加速芯片出现了短缺现象，这无疑给那些高度依赖其技术的企业和研究机构带来了巨大的挑战。

面对这样的挑战，国内市场也展现出了强大的创新能力和应对能力。华为作为中国科技巨头之一，在AI芯片领域取得了显著的突破。其推出的“昇腾”系列芯片，以其性能和针对AI优化的设计，打破NVIDIA在AI领域的绝对领先优势，迅速在国内市场上崭露头角。华为的“昇腾”不仅为国内的AI应用提供了强大的硬件支持，同时也向世界展示了中国在AI芯片设计方面的实力。

本文将对华为“昇腾”系列芯片的性能进行深入分析，探讨它在模型推理方面的优势，以及它如何在国内乃至全球范围内应对AI加速芯片短缺的问题。我们将通过具体的性能数据、应用场景分析等维度，全面解读“昇腾”系列芯片在AI领域的表现。

## 背景

NVIDIA，这个名字在AI加速卡生态领域中几乎是家喻户晓。多年来，凭借其出色的GPU技术，NVIDIA已经建立了不可动摇的市场地位。其CUDA架构原本是为了GPU上的通用计算而设计的，但随着深度学习的兴起，GPU通过特化添加张量核心等硬件优化，逐步负担起了AI工作负载的加速卡的功能。视频图像处理与AI加速之间的紧密联系也变得愈发明显，因为这两者都高度依赖于并行计算的能力。

然而，在AI芯片的市场竞争中，华为“昇腾”系列芯片以其独特的设计和出色的性能，赢得了众多关注。该系列芯片针对视频处理、模型推理和模型训练等不同任务需求，分别推出了视频解析卡（V系列）、推理加速卡（I系列）和训练加速卡（T系列）三大类产品。这三大类产品并非简单地以任务类型来划分，而是深入到了每种任务所需的缓存和算力差异。

视频处理需要高带宽的存储和快速的数据传输能力，以便实时处理大量的图像数据；模型推理则更注重于低功耗和高性能之间的平衡，商业应用则需要高速的模型推理能力和较低的运行成本；而模型训练则是对算力要求最为苛刻的部分，需要大量的计算资源来进行复杂的数学运算，同时需要高速访问内存和存储的能力。正是因为这些需求上的差异，形成了“昇腾”系列芯片中不同的产品大类。

在接下来的文章中，我们将探讨这些不同类别的“昇腾”芯片是如何针对各自的应用场景进行优化设计包装为可实际应用加速卡的，以及它们在性能上相比竞品有哪些异同。

## 视频解析卡（Atlas V系列）

综合评价：

- 算力：★★
- 缓存：★★★
- 功耗：★★
- 硬件功能：针对图像和视频的编码解码，支持H.264、H.265、JPEG等通用编码格式；可同时进行多路视频和图像的编码解码

以官网公布的Atlas 300V为例，使用昇腾310作为核心芯片。其算力为100TOPS(INT8)/50TOPS(FP16)，24GB的LPDDR4X内存，总带宽为204GB/s。设计功耗仅72W。

编码解码能力：

1. 支持H.264 / H.265 硬件解码，100路 1080P 25FPS / 80路 1080P 30FPS / 10路 4K 60FPS

2. 支持H.264 / H.265 硬件编码，30路 1080P 25FPS / 24路 1080P 30FPS / 4路 4K 60FPS

3. JPEG解码能力4K 384FPS，编码能力4K 192FPS，最大分辨率：8192 x 8192

总的来说，该芯片在极低的功耗下，在多路视频处理方面有着不错性能。

## 推理加速卡（Atlas I系列）

- 算力：★★★
- 缓存：★★★★★
- 功耗：★★★

以官网公布的推理卡Atlas 300I-Duo为例，使用昇腾710作为核心芯片，提供140 TOPS(fp16)的算力，搭配单卡高达96G的LPDDRX缓存，而其功耗仅150W。

在大模型的部署中，限制日益增长规模的大模型部署成功与否的关键指标不在算力，而在加速卡的缓存上。如不能将模型参数有效保存在卡内缓存中，而使用内存-加速卡内缓存拷贝（传统低显存推理策略）或同时异构推理（如新近爆火的[llama.cpp](https://github.com/ggerganov/llama.cpp)和[PowerInfer](https://github.com/SJTU-IPADS/PowerInfer)），系统内存-卡内缓存间的通信、CPU-加速卡之间的等待不响应时间、加速卡-CPU极度差异的算力协调成为了限制大参数量模型推理效率的重要因素。

而Atlas 300I-Duo提供了最大的缓存，可以满足更大参数量模型的部署需求。同时还具备相当的计算能力，可以满足大模型的部署需求。

但由现有主流训练架构如cudNN、ROCm等框架中间件训练出的模型，在昇腾所使用的CANN中间件中无法直接使用，而这种转换对模型推理的效率可能存在一定影响。

## 训练加速卡（Atlas T系列）

- 算力：★★★★★
- 缓存：★★★★
- 功耗：★★★★★

以Atlas 300T 训练卡（型号：9000）为例，其基于昇腾910处理器，配合服务器，为数据中心提供强劲算力的训练卡，加快深度学习训练进程。

提供220 TOPS(fp16)的算力，搭配32G高速显存，设计功耗也达到了300W。在提供了相当缓存的基础上，最大化算力，为LLM的在反向传播中大量的算力需求提供了有效支持。


## 总结

与NVIDIA高性能-高功耗（CUDA+GDDR）的策略不同，昇腾Atlas引入了ARM等低功耗架构，并搭配低功耗缓存（LPDDR），在高度自研的基础上，实现了以较少功耗和较低成本完成AI全流程的高效服务。这种策略不仅降低了运行成本，还提高了最多达2.1倍的能效比，为AI应用的广泛应用提供了有力支持。

值得注意的是，昇腾芯片的各系列产品均具备图形处理及AI加速能力，只是在不同的应用场景下有所侧重。无论是视频处理、模型推理还是模型训练，昇腾芯片都能提供针对性的优化和加速，满足多样化的需求。

除了出色的性能和功耗控制外，昇腾芯片还非常注重安全性。在设计和生产过程中，昇腾芯片采用了多种安全技术和加密手段，防止从被入侵的系统中盗取算力及数据。

在日益丰富的昇腾生态的未来，相信一定会有高效、快速、廉价的AI加速芯片走进我们的生活，应用于更多的场景及模型。


## 引用
- [https://zhuanlan.zhihu.com/p/652759391](https://zhuanlan.zhihu.com/p/652759391)
- [https://www.hiascend.com/hardware/accelerator-card?tag=300I-Pro](https://www.hiascend.com/hardware/accelerator-card?tag=300I-Pro)
- [https://www.hiascend.com/hardware/accelerator-card?tag=300V](https://www.hiascend.com/hardware/accelerator-card?tag=300V)
- [https://e.huawei.com/cn/products/computing/ascend/atlas-300t-training-9000](https://e.huawei.com/cn/products/computing/ascend/atlas-300t-training-9000)