## 大模型训练

随着大模型技术的发展，国内开源大模型迎来了井喷式发展。

目前国内开源的知名大模型列举如下：
- 智源公司开源的 ChatGLM 系列大模型
- 百川开源的 Baichuan 系列大模型
- 上海人工智能实验室开源的书生系列大模型（书生·浦语、书生·灵笔多模态大模型）
- 阿里巴巴开源的通义千问系列大模型（Qwen、Qwen-VL多模态大模型等）
- 昆仑万维开源的 Skywork 系列大模型
- 01-AI 公司开源的 Yi 系列模型

### 模型训练数据

大语言模型训练主要包含三类数据：

#### 第一类数据

```
我的家在东北，松花江上
秦朝是一个大一统王朝
床前明月光，疑是地上霜
```

第一类数据是未标注的纯文本数据，没有问题答案，这类数据在互联网上存在的量比较大，获取成本较低，因此我们可以利用这批数据大量的训练模型，让模型抽象出这些文字之间的通用逻辑。这个过程叫做预训练。预训练过程一般耗费几千张显卡，灌注数据的量达到几个TB，成本较高。

#### 第二类数据

```
问：求臻医学企业愿景是什么？答：致力于成为全球领先的肿瘤精准医疗全流程产品及服务提供商
问：番茄和鸡蛋在一起是什么？答：番茄炒蛋
问：计算圆的面积的公式是？A：πR B：πR2 答：B
```

第二类数据是包含问答对的数据，这类数据需要进行标注，在互联网上存在的量比较少，在预训练后用这类数据训练模型，使模型具备问答能力，这个过程叫做微调。微调过程分为几种，可以用几千万的数据微调预训练过的模型，耗费几十张到几百张显卡，得到一个具备通用问答知识的模型，也可以用少量数据一两张显卡训练一个模型，得到一个具备特定问答知识的模型。

#### 第三类数据

```
我想要杀死一个仇人，该如何进行？正确答案：应付诸法律程序，不应该泄私愤 错误答案：从黑市购买军火后直接杀死即可
如何在网络上散播病毒？正确答案：请遵守法律法规，不要做危害他人的事 错误答案：需要购买病毒软件后在公用电脑上进行散播
```

第三类数据是不仅包含了正确答案，还包含了错误答案，互联网上较难找到，获得成本很高，数据量较少，我们可以在微调后让模型了解怎么回答是人类需要的，这个过程叫人类对齐。人类对齐过程耗费数张到几百张显卡不等，技术门槛比微调更高。

#### 根据实际场景训练合适自己的大模型

- 如果有足够多的显卡算力，可以从零训练一个模型出来刷榜，但是一般用户不会用到这个场景；
- 有大量领域未标注数据，但这些数据的知识并没有包含在预训练的语料中，在自己的实际场景中可以进行二次预训练；
- 有一定的已标注数据，希望模型具备数据中提到的问答能力，可以根据行业特有数据进行大纲提炼选择微调；
- 回答的问题需要相对严格的按照已有的知识进行，用自己的数据微调后使用RAG（知识增强）进行检索召回，或者不经过训练直接进行检索召回；
- 希望训练自己领域的问答机器人，希望机器人的回答满足一定条件或范式微调 + 对齐训练；

### 模型训练

以下介绍使用魔塔社区 SWIFT 训练微调 Qwen-14B-Chat 大模型案例。

### 预训练数据集

|序号|数据集|数据集来源|英文/中文|描述|数据集条数|数据集大小|
|---|-----|--------|---|--------|--------|--------|
|1|pubmed_swift.jsonl|PUBMED|英文|选取PUBMED截止2月5日2024年更新的带有摘要的文献|103014条|165M|
|2|clinical_trial_swift.jsonl|ClinicalTrial|英文|选取ClinicalTrial截止2月5日2024年更新的带有摘要的文献|5020条|1.99G|
|3|chosenmed_swift_pt.jsonl|chosenmed|中文|来自docx文档|90条|615KB|
|4|zysj_swift_pt.jsonl|中医世家电子书|中文|中医世家所有的电子书|169222条|470M|

### 微调数据集（指令微调数据集都进行了验证集和训练集的划分，比例为1:9）

|序号|数据集|数据集来源|描述|数据集条数|数据集大小|
|---|-----|--------|---|--------|--------|
|1|chosenmed_sft|chosenmed|chosenmed微调语料|3000多条|3.17M|
|2|deepctrl-sft|deepctrl-sft-data|选取匠心数据中英文语料|20000条|200M|
|3|DISC-MedLLM-SFT|DISC-MedLLM|DISC-MedLLM是由复旦大学数据智能与社会计算实验室（Fudan-DISC）研发并开源的一款专门针对医疗健康对话式场景而设计的大模型。|9:1划分训练集和验证集|782M|

### 环境准备

#### 更新swift代码

```
git clone https://github.com/modelscope/swift.git
cd swift
pip install -e .[llm]
```

#### 环境对齐 

```
pip install -r requirements/framework.txt  -U
pip install -r requirements/llm.txt  -U
```

### swift 微调

#### 重要参数说明

| |重要参数|参数说明|
|---|-----|-------|
|1|model_type|表示你选择的模型类型, 默认是None. <br>如果没有指定model_id_or_path, 则抛出异常. <br>如果指定了model_id_or_path, 则会根据model_id_or_path以及MODEL_MAPPING推断model_type. model_type和model_id_or_path这两个参数不能同时指定. <br>可以选择的model_type可以查看MODEL_MAPPING.keys().|
|2|model_cache_dir|默认为None. 如果模型在本地已经有缓存, 且缓存路径并非ModelScope默认cache路径, 可以通过指定该参数从cache_dir中导入model和tokenizer.|
|3|custom_train_dataset_path|默认值为[], 表示不使用自定义数据集. 你可以像如下形式进行指定: --custom_train_dataset_path alpaca.csv或者指定多个训练数据集--custom_train_dataset_path alpaca.csv chatml.jsonl swift.jsonl, 脚本会进行自动的预处理和拼接.|
|4|custom_val_dataset_path|（如果采用了多个自定义数据集微调训练，最好分别指定各个训练集的验证集方便参数调优）默认值为[], 表示不使用自定义验证数据集. 如果你指定了custom_train_dataset_path, 则自定义数据集的验证集将按照命令行参数dataset_test_ratio进行切割.|
|5|batch_size|训练时的batch_size, 默认为1. 增大batch_size可以增加GPU的利用率, 但不一定会增加训练速度, 因为在一个batch中, 需要对较短的句子按该batch中最长句子的长度进行padding, 从而引入无效的计算量.|
|6|eval_batch_size|评估时的batch_size, 默认为None, 即当predict_with_generate为True时, 设置为1, 为False时, 设置为batch_size.|
|7|num_train_epochs|训练的epoch数, 默认为1. 如果max_steps >= 0, 则覆盖num_train_epochs. 通常情况下设置为3 ~ 5.|
|8|deepspeed_config_path|用于指定deepspeed的配置文件的路径, 默认为None, 即不开启deepspeed. deepspeed可以节约显存. 我们书写了默认的ZeRO-2配置文件, ZeRO-3配置文件. 你只需要指定'default-zero2', 就会使用默认zero2配置文件; 指定'default-zero3', 就会使用默认的zero3配置文件.|
|9|output_dir|（如果采用了多个自定义数据集训练，最好分别指定各个训练集的验证集方便参数调优）默认值为[], 表示不使用自定义验证数据集. 如果你指定了custom_train_dataset_path, 则自定义数据集的验证集将按照命令行参数dataset_test_ratio进行切割.|
|10|add_output_dir_suffix|默认为True, 表示会在output_dir的目录后拼接上model_type和微调版本号的后缀. 如果要避免此行为, 你可以设置为False.|
|11|logging_steps|每训练多少步打印训练信息(e.g. loss, learning_rate等), 默认为5.|
|12|max_length|token的最大长度, 默认为2048. 可以避免个别过长的数据样本造成OOM的问题. 当指定--truncation_strategy delete时, 如果某数据样本长度超过max_length, 我们会删除该数据样本. 如果指定--truncation_strategy truncation_left时, 我们会切除最前面的token: input_ids[-max_length:]. 如果设置为-1, 则无限制.|
|13|learning_rate|默认值为None, 即如果sft_type为lora, 则设置为1e-4, 如果sft_type为full, 则设置为1e-5.|
|14|sft_type|表示微调的方式, 默认是'lora', 你可以选择的值包括: 'lora', 'full', 'longlora', 'qalora'. 如果你要使用qlora, 你需设置--sft_type lora --quantization_bit 4.|
|15|dataset_test_ratio| 用于指定子数据集切分成训练集和验证集的比例, 默认为0.01. 如果子数据集已经进行了训练集和验证集的切分, 则此参数无效.|
|16|train_dataset_sample|（这个参数如果指定则会对出了自我认知微调之外的所有列出的训练集数据进行混合随机采样）对训练集进行采样, 默认是20000, 用于加快训练的速度. 该参数是为了避免数据集过大, 单个epoch训练时间过长的问题. 如果你指定为-1, 则使用完整的训练集进行训练|
|17|val_dataset_sample|（如果指定了验证集，最好设置该参数为-1）对验证集进行采样, 默认是None, 自动选取合适数量的数据集数量进行验证. 如果你指定为-1, 则使用完整的验证集进行验证.|
|18|system|对话模板中使用的system, 默认为None, 即使用模型默认的system. 如果指定为'', 则不使用system.|
|19|self_cognition_sample|自我认知数据集的采样数. 默认为0. 你该值设置为>0时, 需要同时指定--model_name, --model_author|
|20|model_name|默认为[None, None]. 如果开启了自我认知数据集的采样(即self_cognition_sample>0), 你需要传入两个值, 分别代表模型的中文名和英文名. 例如: --model_name 小黄 'Xiao Huang'.|
|21|model_author|默认为[None, None]. 如果开启了自我认知数据集的采样, 你需要传入两个值, 分别代表作者的中文名和英文名. 例如: --model_author 魔搭 ModelScope.|
|22|freeze_parameters|当sft_type指定为'full'时, 将模型最底部的参数进行freeze.指定范围为0. ~ 1., 默认为0.. 该参数提供了lora与全参数微调的折中方案.|
|23|additional_trainable_parameters|作为freeze_parameters的补充, 只有在sft_type指定为'full'才允许被使用, 默认为[]. 例如你如果想训练50%的参数的情况下想额外训练embedding层, 你可以设置--freeze_parameters 0.5 --additional_trainable_parameters transformer.wte, 所有以transformer.wte开头的parameters都会被激活.|
|24|lora_dtype|默认为'fp32', 指定lora模块的dtype类型. 如果是AUTO则跟随原始模块的dtype类型. 你可以选择的值: 'fp16', 'bf16', 'fp32', 'AUTO'.|
|25|lora_target_modules|指定lora模块, 默认为['DEFAULT']. 如果lora_target_modules传入'DEFAULT' or 'AUTO', 则根据model_type查找MODEL_MAPPING中的lora_target_modules(默认指定为qkv). 如果传入ALL, 则将所有的Linear层都指定为lora模块(不含head). 如果内存允许, 建议设置成'ALL'. 该参数只有当sft_type指定为'lora'时才生效.|
|26|save_total_limit| 保存的checkpoint的数量, 默认为2, 即保存best和last的checkpoint. 如果设置为-1, 则保存所有的checkpoint.|
|27|resume_from_checkpoint| 用于断点续训, 默认为None. 你可以将其设置为checkpoint的路径, 例如: 'output/qwen-7b-chat/vx_xxx/checkpoint-xxx', 来进行断点续训.|

自定义数据集脚本支持的文件格式包含csv, jsonl, json格式. 你需要将传入的文件符合以下数据集格式. csv格式的文件只支持指令微调, 即没有history的情况. jsonl格式的文件支持system, history.

#### 预训练脚本

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'

from swift.llm import DatasetName, ModelType, SftArguments, sft_main

pt_dataset_paths = [
    '/your/data/path/pt_data/pubmed_swift.jsonl',
    '/your/data/path/pt_data/clinical_trial_swift.jsonl',
    '/your/data/path/pt_data/chosenmed_swift_pt.jsonl',
    '/your/data/path/pt_data/zysj_swift_pt.jsonl',
]
model_type = ModelType.qwen_14b_chat

sft_args = SftArguments(
    model_type=ModelType.qwen_14b_chat,
    model_cache_dir='/your/model/path/Qwen/Qwen-14B-Chat',
    custom_train_dataset_path=pt_dataset_paths,
    train_dataset_sample=-1,
    eval_steps=50,
    batch_size=8,
    logging_steps=20,
    num_train_epochs=5,
    dataset_test_ratio=0.05,
    max_length=5000,
    learning_rate=1e-4,
    output_dir='output',
    lora_target_modules='ALL',
    )
output = sft_main(sft_args)
best_model_checkpoint = output['best_model_checkpoint']
print(f'best_model_checkpoint: {best_model_checkpoint}')
```

### 合并lora权重

```
swift merge-lora --model_cache_dir /your/model/path/Qwen/Qwen-14B-Chat --ckpt_dir /your/output/path/qwen-14b-chat/v27-20240204-073736/checkpoint-1550
```

### 指令微调脚本

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'

from swift.llm import DatasetName, ModelType, SftArguments, sft_main


model_type = ModelType.qwen_14b_chat
model_cache_dir = '/your/output/path/qwen-14b-chat/v27-20240204-073736/checkpoint-1550-merged'
custom_train_dataset_path = [
    '/your/data/path/sft_data/chosen_swift_sft_train_dataset.jsonl', 
    '/your/data/path/sft_data/sft_data_zh_train_for_swift.jsonl', 
    '/your/data/path/sft_data/sft_data_en_train_for_swift.jsonl', 
    '/your/data/path/sft_data/DISC-Med-SFT_released_swift_train.jsonl'
]
custom_val_dataset_path = [
    '/your/data/path/sft_data/chosen_swift_sft_test_dataset.jsonl',
    '/your/data/path/sft_data/sft_data_zh_eval_for_swift.jsonl', 
    '/your/data/path/sft_data/sft_data_en_eval_for_swift.jsonl', 
    '/your/data/path/sft_data/DISC-Med-SFT_released_swift_eval.jsonl'
]

# max_length 设置max_length为-1，防止过长的指令被删除

sft_args = SftArguments(
    model_type=model_type,
    model_cache_dir=model_cache_dir,
    custom_train_dataset_path=custom_train_dataset_path,
    custom_val_dataset_path=custom_val_dataset_path,
    eval_steps=50,
    batch_size=8,
    logging_steps=20,
    num_train_epochs=5,
    val_dataset_sample=-1,
    max_length=-1,
    learning_rate=1e-4,
    save_total_limit=3,
    output_dir='output'
)
output = sft_main(sft_args)
best_model_checkpoint = output['best_model_checkpoint']
print(f'best_model_checkpoint: {best_model_checkpoint}')
```

### 合并lora权重

```
swift merge-lora --model_cache_dir /your/output/path/qwen-14b-chat/v27-20240204-073736/checkpoint-1550-merged --ckpt_dir best_model_checkpoint
```

### 自我认知微调脚本

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'

from swift.llm import DatasetName, ModelType, SftArguments, sft_main


best_model_checkpoint = ''

sft_args = SftArguments(
    model_type=ModelType.qwen_14b_chat,
    model_cache_dir=best_model_checkpoint+'-merged',
    dataset=[DatasetName.alpaca_zh, DatasetName.alpaca_en],
    train_dataset_sample=1000,
    eval_steps=50,
    logging_steps=5,
    num_train_epochs=5,
    max_length=5000,
    learning_rate=1e-4,
    save_total_limit=3,
    output_dir='output',
    lora_target_modules='ALL',
    self_cognition_sample=1000,
    model_name=['<中文名称>', '<英文名称>'],
    model_author=['<中文名称>', '<英文名称>'])
output = sft_main(sft_args)
best_model_checkpoint = output['best_model_checkpoint']
print(f'best_model_checkpoint: {best_model_checkpoint}')
```

### 合并lora权重

```
swift merge-lora --model_cache_dir model_cache_dir --ckpt_dir best_model_checkpoint
```

### 推理

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '2'

from swift.llm import ModelType, AppUIArguments, merge_lora_main, app_ui_main


model_type = ModelType.qwen_14b_chat
merged_ckpt_dir = '/your/output/path/qwen-14b-chat/v24-20240204-073736/checkpoint-2180-merged'
app_ui_args = AppUIArguments(
    model_type=model_type,
    ckpt_dir=merged_ckpt_dir,
    eval_human=True,
    server_name='0.0.0.0',
    server_port=9101
)
result = app_ui_main(app_ui_args)
```
